Starting at 2023-05-02 08:33:17
EVALUATION: town05
ROUTES: leaderboard/data/evaluation_routes/routes_town05_long.xml
SCENARIOS: leaderboard/data/scenarios/town05_all_scenarios.json
CHECKPOINT_ENDPOINT: results/town05.json

Environment:
NV_CUDA_COMPAT_PACKAGE=cuda-compat-11-3
CONDA_SHLVL=2
PYTHONUNBUFFERED=1
LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64
CONDA_EXE=/opt/conda/bin/conda
RESUME=True
ROUTES=leaderboard/data/evaluation_routes/routes_town05_long.xml
TEAM_AGENT=leaderboard/team_code/interfuser_agent.py
HOSTNAME=211f82c81cbf
LEADERBOARD_ROOT=leaderboard
CARLA_ROOT=carla
CONDA_PREFIX=/opt/conda/envs/interfuser
NV_LIBNPP_VERSION=11.3.3.95-1
NVIDIA_VISIBLE_DEVICES=0
CARLA_SERVER=carla/CarlaUE4.sh
NV_LIBCUSPARSE_VERSION=11.6.0.109-1
_CE_M=
NVIDIA_PRODUCT_NAME=CUDA
CONDA_PREFIX_1=/opt/conda
NCCL_VERSION=2.9.9-1
SCENARIOS=leaderboard/data/scenarios/town05_all_scenarios.json
PWD=/interfuser
NVARCH=x86_64
HOME=/root
CONDA_PYTHON_EXE=/opt/conda/bin/python
LC_CTYPE=C.UTF-8
SDL_VIDEODRIVER=dummy
NV_LIBNCCL_PACKAGE_VERSION=2.9.9-1
NV_LIBNCCL_PACKAGE=libnccl2=2.9.9-1+cuda11.3
NV_CUDA_LIB_VERSION=11.3.1-1
_CE_CONDA=
PORT=2000
NV_LIBNPP_PACKAGE=libnpp-11-3=11.3.3.95-1
NV_LIBNCCL_PACKAGE_NAME=libnccl2
NV_NVTX_VERSION=11.3.109-1
NV_LIBCUBLAS_VERSION=11.5.1.109-1
NV_LIBCUBLAS_PACKAGE=libcublas-11-3=11.5.1.109-1
NV_CUDNN_VERSION=8.2.0.53
CONDA_PROMPT_MODIFIER=(interfuser) 
CHALLENGE_TRACK_CODENAME=SENSORS
CUDA_VERSION=11.3.1
NV_LIBCUBLAS_PACKAGE_NAME=libcublas-11-3
NVIDIA_DRIVER_CAPABILITIES=compute,utility
CONDA_ROOT=/opt/conda
CUDA_VISIBLE_DEVICES=0
SHLVL=2
PYTHONPATH=:carla/PythonAPI:carla/PythonAPI/carla:carla/PythonAPI/carla/dist/carla-0.9.14-py3.7-linux-x86_64.egg:leaderboard:leaderboard/team_code:scenario_runner
NVIDIA_REQUIRE_CUDA=cuda>=11.3 brand=tesla,driver>=418,driver<419 driver>=450
DEBUG_CHALLENGE=0
EVALUATION=town05
NV_CUDA_CUDART_VERSION=11.3.109-1
TM_PORT=2500
NV_CUDNN_PACKAGE_NAME=libcudnn8
PATH=/opt/conda/envs/interfuser/bin:/opt/conda/condabin:/opt/conda/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
REPETITIONS=1
CONDA_DEFAULT_ENV=interfuser
SAVE_PATH=data/eval
CHECKPOINT_ENDPOINT=results/town05.json
NV_CUDNN_PACKAGE=libcudnn8=8.2.0.53-1+cuda11.3
TEAM_CONFIG=leaderboard/team_code/interfuser_config.py
_=/usr/bin/env
---------------------

WARNING: Version mismatch detected: You are trying to connect to a simulator that might be incompatible with this API 
WARNING: Client API version     = 0.9.14 
WARNING: Simulator API version  = 0.9.14-dirty 
leaderboard/leaderboard/leaderboard_evaluator.py:93: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  if LooseVersion(dist.version) < LooseVersion('0.9.14'):
pygame 2.1.2 (SDL 2.0.16, Python 3.7.16)
Hello from the pygame community. https://www.pygame.org/contribute.html

[1m========= Preparing RouteScenario_16 (repetition 0) =========
> Setting up the agent[0m
Downloading: "https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/resnet50d_ra2-464e36ba.pth" to /root/.cache/torch/hub/checkpoints/resnet50d_ra2-464e36ba.pth
load model: models/interfuser.pth.tar
[1m> Loading the world[0m
load
load
load
load
load
load
load
[1m> Running the route[0m
[1m> Stopping the route[0m

[1m========= Results of RouteScenario_16 (repetition 0) ------ [91mFAILURE[0m [1m=========[0m

╒═════════════════════════════════╤═════════════════════╕
│ Start Time                      │ 2023-05-02 08:35:33 │
├─────────────────────────────────┼─────────────────────┤
│ End Time                        │ 2023-05-02 09:19:39 │
├─────────────────────────────────┼─────────────────────┤
│ Duration (System Time)          │ 2645.83s            │
├─────────────────────────────────┼─────────────────────┤
│ Duration (Game Time)            │ 448.35s             │
├─────────────────────────────────┼─────────────────────┤
│ Ratio (System Time / Game Time) │ 0.169               │
╘═════════════════════════════════╧═════════════════════╛

╒═══════════════════════╤═════════╤═════════╕
│ Criterion             │ Result  │ Value   │
├───────────────────────┼─────────┼─────────┤
│ RouteCompletionTest   │ [92mSUCCESS[0m │ 100 %   │
├───────────────────────┼─────────┼─────────┤
│ OutsideRouteLanesTest │ [91mFAILURE[0m │ 3.87 %  │
├───────────────────────┼─────────┼─────────┤
│ CollisionTest         │ [91mFAILURE[0m │ 4 times │
├───────────────────────┼─────────┼─────────┤
│ RunningRedLightTest   │ [91mFAILURE[0m │ 3 times │
├───────────────────────┼─────────┼─────────┤
│ RunningStopTest       │ [92mSUCCESS[0m │ 0 times │
├───────────────────────┼─────────┼─────────┤
│ InRouteTest           │ [92mSUCCESS[0m │         │
├───────────────────────┼─────────┼─────────┤
│ AgentBlockedTest      │ [92mSUCCESS[0m │         │
├───────────────────────┼─────────┼─────────┤
│ Timeout               │ [92mSUCCESS[0m │         │
╘═══════════════════════╧═════════╧═════════╛

[1m> Registering the route statistics[0m

[1m========= Preparing RouteScenario_17 (repetition 0) =========
> Setting up the agent[0m
load model: models/interfuser.pth.tar
[1m> Loading the world[0m
load
load
load
load
load
load
load
[1m> Running the route[0m
ERROR: failed to destroy actor 510 : unable to destroy actor: not found 
ERROR: failed to destroy actor 475 : unable to destroy actor: not found 
[1m> Stopping the route[0m

[1m========= Results of RouteScenario_17 (repetition 0) ------ [92mSUCCESS[0m [1m=========[0m

╒═════════════════════════════════╤═════════════════════╕
│ Start Time                      │ 2023-05-02 09:21:02 │
├─────────────────────────────────┼─────────────────────┤
│ End Time                        │ 2023-05-02 10:03:44 │
├─────────────────────────────────┼─────────────────────┤
│ Duration (System Time)          │ 2562.16s            │
├─────────────────────────────────┼─────────────────────┤
│ Duration (Game Time)            │ 606.7s              │
├─────────────────────────────────┼─────────────────────┤
│ Ratio (System Time / Game Time) │ 0.237               │
╘═════════════════════════════════╧═════════════════════╛

╒═══════════════════════╤═════════╤═════════╕
│ Criterion             │ Result  │ Value   │
├───────────────────────┼─────────┼─────────┤
│ RouteCompletionTest   │ [92mSUCCESS[0m │ 100 %   │
├───────────────────────┼─────────┼─────────┤
│ OutsideRouteLanesTest │ [92mSUCCESS[0m │ 0 %     │
├───────────────────────┼─────────┼─────────┤
│ CollisionTest         │ [92mSUCCESS[0m │ 0 times │
├───────────────────────┼─────────┼─────────┤
│ RunningRedLightTest   │ [92mSUCCESS[0m │ 0 times │
├───────────────────────┼─────────┼─────────┤
│ RunningStopTest       │ [92mSUCCESS[0m │ 0 times │
├───────────────────────┼─────────┼─────────┤
│ InRouteTest           │ [92mSUCCESS[0m │         │
├───────────────────────┼─────────┼─────────┤
│ AgentBlockedTest      │ [92mSUCCESS[0m │         │
├───────────────────────┼─────────┼─────────┤
│ Timeout               │ [92mSUCCESS[0m │         │
╘═══════════════════════╧═════════╧═════════╛

[1m> Registering the route statistics[0m
WARNING: attempting to destroy an actor that is already dead: Actor 543 (vehicle.seat.leon) 
WARNING: attempting to destroy an actor that is already dead: Actor 544 (vehicle.volkswagen.t2_2021) 
WARNING: attempting to destroy an actor that is already dead: Actor 549 (vehicle.bmw.grandtourer) 
WARNING: attempting to destroy an actor that is already dead: Actor 582 (vehicle.harley-davidson.low_rider) 
WARNING: attempting to destroy an actor that is already dead: Actor 600 (vehicle.tesla.cybertruck) 
WARNING: attempting to destroy an actor that is already dead: Actor 601 (vehicle.ford.crown) 
WARNING: attempting to destroy an actor that is already dead: Actor 624 (vehicle.ford.crown) 
WARNING: attempting to destroy an actor that is already dead: Actor 630 (vehicle.citroen.c3) 
WARNING: attempting to destroy an actor that is already dead: Actor 633 (vehicle.micro.microlino) 
WARNING: attempting to destroy an actor that is already dead: Actor 634 (vehicle.mercedes.coupe_2020) 
WARNING: attempting to destroy an actor that is already dead: Actor 637 (vehicle.kia.e-niro) 

[1m========= Preparing RouteScenario_18 (repetition 0) =========
> Setting up the agent[0m
load model: models/interfuser.pth.tar
[1m> Loading the world[0m
load
load
load
load
load
load
load
Base transform is blocking objects  Transform(Location(x=-59.311008, y=-106.639061, z=0.600000), Rotation(pitch=0.000000, yaw=-12.545258, roll=0.000000))
Base transform is blocking objects  Transform(Location(x=-59.311008, y=-106.639061, z=0.600000), Rotation(pitch=0.000000, yaw=-12.545258, roll=0.000000))
Base transform is blocking objects  Transform(Location(x=-59.311008, y=-106.639061, z=0.600000), Rotation(pitch=0.000000, yaw=-12.545258, roll=0.000000))
[1m> Running the route[0m
/interfuser/leaderboard/team_code/tracker.py:141: RuntimeWarning: divide by zero encountered in double_scalars
  speed = 0.5 * self.frequency * np.sqrt((prev_pos[0]-cur_pos[0])**2+(prev_pos[1]-cur_pos[1])**2) / (to.historical_steps[i+1]-to.historical_steps[i])
ERROR: failed to destroy actor 803 : unable to destroy actor: not found 
[1m> Stopping the route[0m

[1m========= Results of RouteScenario_18 (repetition 0) ------ [91mFAILURE[0m [1m=========[0m

╒═════════════════════════════════╤═════════════════════╕
│ Start Time                      │ 2023-05-02 10:05:28 │
├─────────────────────────────────┼─────────────────────┤
│ End Time                        │ 2023-05-02 10:36:35 │
├─────────────────────────────────┼─────────────────────┤
│ Duration (System Time)          │ 1866.79s            │
├─────────────────────────────────┼─────────────────────┤
│ Duration (Game Time)            │ 281.7s              │
├─────────────────────────────────┼─────────────────────┤
│ Ratio (System Time / Game Time) │ 0.151               │
╘═════════════════════════════════╧═════════════════════╛

╒═══════════════════════╤═════════╤═════════╕
│ Criterion             │ Result  │ Value   │
├───────────────────────┼─────────┼─────────┤
│ RouteCompletionTest   │ [92mSUCCESS[0m │ 100 %   │
├───────────────────────┼─────────┼─────────┤
│ OutsideRouteLanesTest │ [92mSUCCESS[0m │ 0 %     │
├───────────────────────┼─────────┼─────────┤
│ CollisionTest         │ [92mSUCCESS[0m │ 0 times │
├───────────────────────┼─────────┼─────────┤
│ RunningRedLightTest   │ [91mFAILURE[0m │ 5 times │
├───────────────────────┼─────────┼─────────┤
│ RunningStopTest       │ [92mSUCCESS[0m │ 0 times │
├───────────────────────┼─────────┼─────────┤
│ InRouteTest           │ [92mSUCCESS[0m │         │
├───────────────────────┼─────────┼─────────┤
│ AgentBlockedTest      │ [92mSUCCESS[0m │         │
├───────────────────────┼─────────┼─────────┤
│ Timeout               │ [92mSUCCESS[0m │         │
╘═══════════════════════╧═════════╧═════════╛

[1m> Registering the route statistics[0m

[1m========= Preparing RouteScenario_19 (repetition 0) =========
> Setting up the agent[0m
load model: models/interfuser.pth.tar
[1m> Loading the world[0m
load
load
load
load
load
load
load
[1m> Running the route[0m
ERROR: failed to destroy actor 1111 : unable to destroy actor: not found 
[1m> Stopping the route[0m

[1m========= Results of RouteScenario_19 (repetition 0) ------ [91mFAILURE[0m [1m=========[0m

╒═════════════════════════════════╤═════════════════════╕
│ Start Time                      │ 2023-05-02 10:39:16 │
├─────────────────────────────────┼─────────────────────┤
│ End Time                        │ 2023-05-02 11:25:58 │
├─────────────────────────────────┼─────────────────────┤
│ Duration (System Time)          │ 2802.38s            │
├─────────────────────────────────┼─────────────────────┤
│ Duration (Game Time)            │ 409.15s             │
├─────────────────────────────────┼─────────────────────┤
│ Ratio (System Time / Game Time) │ 0.146               │
╘═════════════════════════════════╧═════════════════════╛

╒═══════════════════════╤═════════╤═════════╕
│ Criterion             │ Result  │ Value   │
├───────────────────────┼─────────┼─────────┤
│ RouteCompletionTest   │ [92mSUCCESS[0m │ 100 %   │
├───────────────────────┼─────────┼─────────┤
│ OutsideRouteLanesTest │ [92mSUCCESS[0m │ 0 %     │
├───────────────────────┼─────────┼─────────┤
│ CollisionTest         │ [91mFAILURE[0m │ 1 times │
├───────────────────────┼─────────┼─────────┤
│ RunningRedLightTest   │ [91mFAILURE[0m │ 2 times │
├───────────────────────┼─────────┼─────────┤
│ RunningStopTest       │ [92mSUCCESS[0m │ 0 times │
├───────────────────────┼─────────┼─────────┤
│ InRouteTest           │ [92mSUCCESS[0m │         │
├───────────────────────┼─────────┼─────────┤
│ AgentBlockedTest      │ [92mSUCCESS[0m │         │
├───────────────────────┼─────────┼─────────┤
│ Timeout               │ [92mSUCCESS[0m │         │
╘═══════════════════════╧═════════╧═════════╛

[1m> Registering the route statistics[0m

[1m========= Preparing RouteScenario_20 (repetition 0) =========
> Setting up the agent[0m
load model: models/interfuser.pth.tar
[1m> Loading the world[0m
load
load
load
load
load
load
load
Base transform is blocking objects  Transform(Location(x=39.997688, y=-77.031784, z=0.600000), Rotation(pitch=0.000000, yaw=541.532104, roll=0.000000))
[1m> Running the route[0m

Finished at 2023-05-02 11:41:30

Starting at 2023-05-02 11:41:32
EVALUATION: town05
ROUTES: leaderboard/data/evaluation_routes/routes_town05_long.xml
SCENARIOS: leaderboard/data/scenarios/town05_all_scenarios.json
CHECKPOINT_ENDPOINT: results/town05.json

Environment:
NV_CUDA_COMPAT_PACKAGE=cuda-compat-11-3
CONDA_SHLVL=2
PYTHONUNBUFFERED=1
LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64
CONDA_EXE=/opt/conda/bin/conda
RESUME=True
ROUTES=leaderboard/data/evaluation_routes/routes_town05_long.xml
TEAM_AGENT=leaderboard/team_code/interfuser_agent.py
HOSTNAME=211f82c81cbf
LEADERBOARD_ROOT=leaderboard
CARLA_ROOT=carla
CONDA_PREFIX=/opt/conda/envs/interfuser
NV_LIBNPP_VERSION=11.3.3.95-1
NVIDIA_VISIBLE_DEVICES=0
CARLA_SERVER=carla/CarlaUE4.sh
NV_LIBCUSPARSE_VERSION=11.6.0.109-1
_CE_M=
NVIDIA_PRODUCT_NAME=CUDA
CONDA_PREFIX_1=/opt/conda
NCCL_VERSION=2.9.9-1
SCENARIOS=leaderboard/data/scenarios/town05_all_scenarios.json
PWD=/interfuser
NVARCH=x86_64
HOME=/root
CONDA_PYTHON_EXE=/opt/conda/bin/python
LC_CTYPE=C.UTF-8
SDL_VIDEODRIVER=dummy
NV_LIBNCCL_PACKAGE_VERSION=2.9.9-1
NV_LIBNCCL_PACKAGE=libnccl2=2.9.9-1+cuda11.3
NV_CUDA_LIB_VERSION=11.3.1-1
_CE_CONDA=
PORT=2000
NV_LIBNPP_PACKAGE=libnpp-11-3=11.3.3.95-1
NV_LIBNCCL_PACKAGE_NAME=libnccl2
NV_NVTX_VERSION=11.3.109-1
NV_LIBCUBLAS_VERSION=11.5.1.109-1
NV_LIBCUBLAS_PACKAGE=libcublas-11-3=11.5.1.109-1
NV_CUDNN_VERSION=8.2.0.53
CONDA_PROMPT_MODIFIER=(interfuser) 
CHALLENGE_TRACK_CODENAME=SENSORS
CUDA_VERSION=11.3.1
NV_LIBCUBLAS_PACKAGE_NAME=libcublas-11-3
NVIDIA_DRIVER_CAPABILITIES=compute,utility
CONDA_ROOT=/opt/conda
CUDA_VISIBLE_DEVICES=0
SHLVL=2
PYTHONPATH=:carla/PythonAPI:carla/PythonAPI/carla:carla/PythonAPI/carla/dist/carla-0.9.14-py3.7-linux-x86_64.egg:leaderboard:leaderboard/team_code:scenario_runner
NVIDIA_REQUIRE_CUDA=cuda>=11.3 brand=tesla,driver>=418,driver<419 driver>=450
DEBUG_CHALLENGE=0
EVALUATION=town05
NV_CUDA_CUDART_VERSION=11.3.109-1
TM_PORT=2500
NV_CUDNN_PACKAGE_NAME=libcudnn8
PATH=/opt/conda/envs/interfuser/bin:/opt/conda/condabin:/opt/conda/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
REPETITIONS=1
CONDA_DEFAULT_ENV=interfuser
SAVE_PATH=data/eval
CHECKPOINT_ENDPOINT=results/town05.json
NV_CUDNN_PACKAGE=libcudnn8=8.2.0.53-1+cuda11.3
TEAM_CONFIG=leaderboard/team_code/interfuser_config.py
_=/usr/bin/env
---------------------

WARNING: Version mismatch detected: You are trying to connect to a simulator that might be incompatible with this API 
WARNING: Client API version     = 0.9.14 
WARNING: Simulator API version  = 0.9.14-dirty 
leaderboard/leaderboard/leaderboard_evaluator.py:93: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  if LooseVersion(dist.version) < LooseVersion('0.9.14'):
pygame 2.1.2 (SDL 2.0.16, Python 3.7.16)
Hello from the pygame community. https://www.pygame.org/contribute.html

[1m========= Preparing RouteScenario_20 (repetition 0) =========
> Setting up the agent[0m
load model: models/interfuser.pth.tar

[91mCould not set up the required agent:
> CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 23.63 GiB total capacity; 255.48 MiB already allocated; 293.06 MiB free; 270.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF[0m

Traceback (most recent call last):
  File "leaderboard/leaderboard/leaderboard_evaluator.py", line 272, in _load_and_run_scenario
    self.agent_instance = getattr(self.module_agent, agent_class_name)(args.agent_config)
  File "/interfuser/leaderboard/leaderboard/autoagents/autonomous_agent.py", line 45, in __init__
    self.setup(path_to_conf_file)
  File "leaderboard/team_code/interfuser_agent.py", line 210, in setup
    self.net.load_state_dict(torch.load(path_to_model_file)["state_dict"])
  File "/opt/conda/envs/interfuser/lib/python3.7/site-packages/torch/serialization.py", line 789, in load
    return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
  File "/opt/conda/envs/interfuser/lib/python3.7/site-packages/torch/serialization.py", line 1131, in _load
    result = unpickler.load()
  File "/opt/conda/envs/interfuser/lib/python3.7/site-packages/torch/serialization.py", line 1101, in persistent_load
    load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
  File "/opt/conda/envs/interfuser/lib/python3.7/site-packages/torch/serialization.py", line 1083, in load_tensor
    wrap_storage=restore_location(storage, location),
  File "/opt/conda/envs/interfuser/lib/python3.7/site-packages/torch/serialization.py", line 215, in default_restore_location
    result = fn(storage, location)
  File "/opt/conda/envs/interfuser/lib/python3.7/site-packages/torch/serialization.py", line 187, in _cuda_deserialize
    return obj.cuda(device)
  File "/opt/conda/envs/interfuser/lib/python3.7/site-packages/torch/_utils.py", line 81, in _cuda
    self.size(), device=torch.device("cuda")
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 23.63 GiB total capacity; 255.48 MiB already allocated; 293.06 MiB free; 270.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[1m> Registering the route statistics[0m

[1m========= Preparing RouteScenario_21 (repetition 0) =========
> Setting up the agent[0m
load model: models/interfuser.pth.tar

[91mCould not set up the required agent:
> CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 23.63 GiB total capacity; 255.48 MiB already allocated; 293.06 MiB free; 270.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF[0m

Traceback (most recent call last):
  File "leaderboard/leaderboard/leaderboard_evaluator.py", line 272, in _load_and_run_scenario
    self.agent_instance = getattr(self.module_agent, agent_class_name)(args.agent_config)
  File "/interfuser/leaderboard/leaderboard/autoagents/autonomous_agent.py", line 45, in __init__
    self.setup(path_to_conf_file)
  File "leaderboard/team_code/interfuser_agent.py", line 210, in setup
    self.net.load_state_dict(torch.load(path_to_model_file)["state_dict"])
  File "/opt/conda/envs/interfuser/lib/python3.7/site-packages/torch/serialization.py", line 789, in load
    return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
  File "/opt/conda/envs/interfuser/lib/python3.7/site-packages/torch/serialization.py", line 1131, in _load
    result = unpickler.load()
  File "/opt/conda/envs/interfuser/lib/python3.7/site-packages/torch/serialization.py", line 1101, in persistent_load
    load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
  File "/opt/conda/envs/interfuser/lib/python3.7/site-packages/torch/serialization.py", line 1083, in load_tensor
    wrap_storage=restore_location(storage, location),
  File "/opt/conda/envs/interfuser/lib/python3.7/site-packages/torch/serialization.py", line 215, in default_restore_location
    result = fn(storage, location)
  File "/opt/conda/envs/interfuser/lib/python3.7/site-packages/torch/serialization.py", line 187, in _cuda_deserialize
    return obj.cuda(device)
  File "/opt/conda/envs/interfuser/lib/python3.7/site-packages/torch/_utils.py", line 81, in _cuda
    self.size(), device=torch.device("cuda")
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 23.63 GiB total capacity; 255.48 MiB already allocated; 293.06 MiB free; 270.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[1m> Registering the route statistics[0m

[1m========= Preparing RouteScenario_22 (repetition 0) =========
> Setting up the agent[0m
load model: models/interfuser.pth.tar

[91mCould not set up the required agent:
> CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 23.63 GiB total capacity; 255.48 MiB already allocated; 293.06 MiB free; 270.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF[0m

Traceback (most recent call last):
  File "leaderboard/leaderboard/leaderboard_evaluator.py", line 272, in _load_and_run_scenario
    self.agent_instance = getattr(self.module_agent, agent_class_name)(args.agent_config)
  File "/interfuser/leaderboard/leaderboard/autoagents/autonomous_agent.py", line 45, in __init__
    self.setup(path_to_conf_file)
  File "leaderboard/team_code/interfuser_agent.py", line 210, in setup
    self.net.load_state_dict(torch.load(path_to_model_file)["state_dict"])
  File "/opt/conda/envs/interfuser/lib/python3.7/site-packages/torch/serialization.py", line 789, in load
    return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
  File "/opt/conda/envs/interfuser/lib/python3.7/site-packages/torch/serialization.py", line 1131, in _load
    result = unpickler.load()
  File "/opt/conda/envs/interfuser/lib/python3.7/site-packages/torch/serialization.py", line 1101, in persistent_load
    load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
  File "/opt/conda/envs/interfuser/lib/python3.7/site-packages/torch/serialization.py", line 1083, in load_tensor
    wrap_storage=restore_location(storage, location),
  File "/opt/conda/envs/interfuser/lib/python3.7/site-packages/torch/serialization.py", line 215, in default_restore_location
    result = fn(storage, location)
  File "/opt/conda/envs/interfuser/lib/python3.7/site-packages/torch/serialization.py", line 187, in _cuda_deserialize
    return obj.cuda(device)
  File "/opt/conda/envs/interfuser/lib/python3.7/site-packages/torch/_utils.py", line 81, in _cuda
    self.size(), device=torch.device("cuda")
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 23.63 GiB total capacity; 255.48 MiB already allocated; 293.06 MiB free; 270.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[1m> Registering the route statistics[0m

[1m========= Preparing RouteScenario_23 (repetition 0) =========
> Setting up the agent[0m
load model: models/interfuser.pth.tar

[91mCould not set up the required agent:
> CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 23.63 GiB total capacity; 255.48 MiB already allocated; 285.06 MiB free; 270.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF[0m

Traceback (most recent call last):
  File "leaderboard/leaderboard/leaderboard_evaluator.py", line 272, in _load_and_run_scenario
    self.agent_instance = getattr(self.module_agent, agent_class_name)(args.agent_config)
  File "/interfuser/leaderboard/leaderboard/autoagents/autonomous_agent.py", line 45, in __init__
    self.setup(path_to_conf_file)
  File "leaderboard/team_code/interfuser_agent.py", line 210, in setup
    self.net.load_state_dict(torch.load(path_to_model_file)["state_dict"])
  File "/opt/conda/envs/interfuser/lib/python3.7/site-packages/torch/serialization.py", line 789, in load
    return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
  File "/opt/conda/envs/interfuser/lib/python3.7/site-packages/torch/serialization.py", line 1131, in _load
    result = unpickler.load()
  File "/opt/conda/envs/interfuser/lib/python3.7/site-packages/torch/serialization.py", line 1101, in persistent_load
    load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
  File "/opt/conda/envs/interfuser/lib/python3.7/site-packages/torch/serialization.py", line 1083, in load_tensor
    wrap_storage=restore_location(storage, location),
  File "/opt/conda/envs/interfuser/lib/python3.7/site-packages/torch/serialization.py", line 215, in default_restore_location
    result = fn(storage, location)
  File "/opt/conda/envs/interfuser/lib/python3.7/site-packages/torch/serialization.py", line 187, in _cuda_deserialize
    return obj.cuda(device)
  File "/opt/conda/envs/interfuser/lib/python3.7/site-packages/torch/_utils.py", line 81, in _cuda
    self.size(), device=torch.device("cuda")
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 23.63 GiB total capacity; 255.48 MiB already allocated; 285.06 MiB free; 270.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[1m> Registering the route statistics[0m

[1m========= Preparing RouteScenario_24 (repetition 0) =========
> Setting up the agent[0m
load model: models/interfuser.pth.tar

[91mCould not set up the required agent:
> CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 23.63 GiB total capacity; 255.48 MiB already allocated; 285.06 MiB free; 270.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF[0m

Traceback (most recent call last):
  File "leaderboard/leaderboard/leaderboard_evaluator.py", line 272, in _load_and_run_scenario
    self.agent_instance = getattr(self.module_agent, agent_class_name)(args.agent_config)
  File "/interfuser/leaderboard/leaderboard/autoagents/autonomous_agent.py", line 45, in __init__
    self.setup(path_to_conf_file)
  File "leaderboard/team_code/interfuser_agent.py", line 210, in setup
    self.net.load_state_dict(torch.load(path_to_model_file)["state_dict"])
  File "/opt/conda/envs/interfuser/lib/python3.7/site-packages/torch/serialization.py", line 789, in load
    return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
  File "/opt/conda/envs/interfuser/lib/python3.7/site-packages/torch/serialization.py", line 1131, in _load
    result = unpickler.load()
  File "/opt/conda/envs/interfuser/lib/python3.7/site-packages/torch/serialization.py", line 1101, in persistent_load
    load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
  File "/opt/conda/envs/interfuser/lib/python3.7/site-packages/torch/serialization.py", line 1083, in load_tensor
    wrap_storage=restore_location(storage, location),
  File "/opt/conda/envs/interfuser/lib/python3.7/site-packages/torch/serialization.py", line 215, in default_restore_location
    result = fn(storage, location)
  File "/opt/conda/envs/interfuser/lib/python3.7/site-packages/torch/serialization.py", line 187, in _cuda_deserialize
    return obj.cuda(device)
  File "/opt/conda/envs/interfuser/lib/python3.7/site-packages/torch/_utils.py", line 81, in _cuda
    self.size(), device=torch.device("cuda")
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 23.63 GiB total capacity; 255.48 MiB already allocated; 285.06 MiB free; 270.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[1m> Registering the route statistics[0m

[1m========= Preparing RouteScenario_25 (repetition 0) =========
> Setting up the agent[0m
load model: models/interfuser.pth.tar

[91mCould not set up the required agent:
> CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 23.63 GiB total capacity; 255.48 MiB already allocated; 285.06 MiB free; 270.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF[0m

Traceback (most recent call last):
  File "leaderboard/leaderboard/leaderboard_evaluator.py", line 272, in _load_and_run_scenario
    self.agent_instance = getattr(self.module_agent, agent_class_name)(args.agent_config)
  File "/interfuser/leaderboard/leaderboard/autoagents/autonomous_agent.py", line 45, in __init__
    self.setup(path_to_conf_file)
  File "leaderboard/team_code/interfuser_agent.py", line 210, in setup
    self.net.load_state_dict(torch.load(path_to_model_file)["state_dict"])
  File "/opt/conda/envs/interfuser/lib/python3.7/site-packages/torch/serialization.py", line 789, in load
    return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
  File "/opt/conda/envs/interfuser/lib/python3.7/site-packages/torch/serialization.py", line 1131, in _load
    result = unpickler.load()
  File "/opt/conda/envs/interfuser/lib/python3.7/site-packages/torch/serialization.py", line 1101, in persistent_load
    load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
  File "/opt/conda/envs/interfuser/lib/python3.7/site-packages/torch/serialization.py", line 1083, in load_tensor
    wrap_storage=restore_location(storage, location),
  File "/opt/conda/envs/interfuser/lib/python3.7/site-packages/torch/serialization.py", line 215, in default_restore_location
    result = fn(storage, location)
  File "/opt/conda/envs/interfuser/lib/python3.7/site-packages/torch/serialization.py", line 187, in _cuda_deserialize
    return obj.cuda(device)
  File "/opt/conda/envs/interfuser/lib/python3.7/site-packages/torch/_utils.py", line 81, in _cuda
    self.size(), device=torch.device("cuda")
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 23.63 GiB total capacity; 255.48 MiB already allocated; 285.06 MiB free; 270.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[1m> Registering the route statistics[0m
[1m> Registering the global statistics[0m

Finished at 2023-05-02 11:41:54

